{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m Here is a potential synopsis for a play titled \"The Moon of Seoul\":\n",
      "\n",
      "It is the 1960s in Seoul, South Korea. Young-sook is a bright yet shy farm girl who dreams of becoming a famous singer in the city one day. When her childhood friend Min-jun returns from studying abroad, sparks fly between them. However, Min-jun must focus on taking over his father's successful business instead of pursuing his passion for art and music. \n",
      "\n",
      "When Young-sook auditions for a spot on a popular television singing competition, she wows the judges with her beautiful voice. As she advances through the competition rounds, her fame grows. Young-sook gets a chance to move to Seoul and sign a record deal, putting her dream within reach.\n",
      "\n",
      "But the fame and fortune quickly go to Young-sook's head. She turns arrogant and loses touch with her humble roots. Min-jun tries to reconnect with Young-sook and remind her of who she really is, but she pushes him away. On the night of the singing competition finale, Young-sook freezes on stage, realizing she lost herself in the glittering world of Seoul. \n",
      "\n",
      "Heartbroken, Young-sook returns home and reconnect\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m Here is a potential review for the play \"The Moon of Seoul\":\n",
      "\n",
      "The Moon of Seoul is a heartwarming coming-of-age story that explores the allure of fame and the importance of staying true to oneself. Playwright Lee Jae-won's tale follows Young-sook, a small-town girl with big dreams of stardom, as she journeys from her rural hometown to the bright lights of 1960s Seoul after wowing judges on a televised singing competition.  \n",
      "\n",
      "As Young-sook advances through the competition rounds, seasoned actress Park Min-jung does an excellent job capturing her initial wide-eyed excitement and talent. But Park also deftly conveys the subtler changes in Young-sook as fame and fortune begin going to her head. No longer the humble, shy girl from the countryside, Young-sook becomes arrogant and intoxicated by her celebrity status.  \n",
      "\n",
      "In contrast, rising star Choi Min-ho gives a subdued yet moving performance as Min-jun, Young-sook's childhood friend who sees through the glitz and tries to save her from losing herself. The pair have an endearing chemistry on stage that evolves into a tender, conflicted relationship.\n",
      "\n",
      "Lee\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Here is a potential review for the play \"The Moon of Seoul\":\n",
      "\n",
      "The Moon of Seoul is a heartwarming coming-of-age story that explores the allure of fame and the importance of staying true to oneself. Playwright Lee Jae-won's tale follows Young-sook, a small-town girl with big dreams of stardom, as she journeys from her rural hometown to the bright lights of 1960s Seoul after wowing judges on a televised singing competition.  \n",
      "\n",
      "As Young-sook advances through the competition rounds, seasoned actress Park Min-jung does an excellent job capturing her initial wide-eyed excitement and talent. But Park also deftly conveys the subtler changes in Young-sook as fame and fortune begin going to her head. No longer the humble, shy girl from the countryside, Young-sook becomes arrogant and intoxicated by her celebrity status.  \n",
      "\n",
      "In contrast, rising star Choi Min-ho gives a subdued yet moving performance as Min-jun, Young-sook's childhood friend who sees through the glitz and tries to save her from losing herself. The pair have an endearing chemistry on stage that evolves into a tender, conflicted relationship.\n",
      "\n",
      "Lee\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "bedrock = Bedrock(\n",
    "  credentials_profile_name=\"default\",\n",
    "  model_id=\"anthropic.claude-v2\"\n",
    ")\n",
    "\n",
    "# First Chain \n",
    "template = \"\"\" you are a playwright. when you get title of theater, your role is writing synopsis.\n",
    "title : {title}\n",
    "synopsis : \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=[\"title\"],\n",
    "  template=template\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(\n",
    "  llm=bedrock,\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "# Second Chain\n",
    "template2 = \"\"\" You are a theater critic. Given a synopsis of a play, your job is to write a review of it.\n",
    "synopsis : {synopsis}\n",
    "review :\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "  input_variables=[\"synopsis\"],\n",
    "  template=template2\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(\n",
    "  llm=bedrock,\n",
    "  prompt=prompt2\n",
    ")\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "#Connect two chain with SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "print(overall_chain.run(\"The Moon of Seoul\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "제1장: 데이터 프 : 283\n",
      "제2장: 울프 코퍼 : 163\n",
      "제3장: 배신과 재 : 274\n",
      "제4장: 울프 코퍼 : 207\n",
      "제5장: 결전의 순 : 295\n",
      "제7장: 새로운 시 : 191\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "with open(\"../data/akazukin_all.txt\", encoding='UTF8') as f:\n",
    "  test_all = f.read()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=300, chunk_overlap=20)\n",
    "\n",
    "texts = text_splitter.split_text(test_all)\n",
    "\n",
    "print(len(texts))\n",
    "\n",
    "for text in texts:\n",
    "  print(text[:10], \":\", len(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in d:\\codes\\yknlp\\lib\\site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_texts(\n",
    "  texts=texts, #Chunk array\n",
    "  embedding=BedrockEmbeddings() #embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "  llm=bedrock,\n",
    "  chain_type=\"stuff\",\n",
    "  retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 제3장에 따르면, 미코의 어릴 적 친구이자 해커 집단 일원인 료가 미코의 소꿉친구입니다. 따라서 정답은 료입니다.\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.run(\"미코의 소꿉친구 이름은?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas=[\n",
    "  {\"source\": \"chapter 1\"},\n",
    "  {\"source\": \"chapter 2\"},\n",
    "  {\"source\": \"chapter 3\"},\n",
    "  {\"source\": \"chapter 4\"},\n",
    "  {\"source\": \"chapter 5~6\"},\n",
    "  {\"source\": \"chapter 7\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# Create Vector database\n",
    "docsearch = FAISS.from_texts(\n",
    "  texts=texts,\n",
    "  embedding=BedrockEmbeddings(),\n",
    "  metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '미코의 친구 이름은?', 'answer': ' 문서 내용에 따르면 미코의 친구 이름은 료입니다.\\n\\n', 'sources': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "llm_bedrock = Bedrock(\n",
    "    credentials_profile_name=\"default\", \n",
    "    model_id=\"anthropic.claude-v2\"\n",
    ")\n",
    "\n",
    "qa_chain_source = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "  llm=llm_bedrock,\n",
    "  chain_type=\"stuff\",\n",
    "  retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "print(qa_chain_source({\"question\" : \"미코의 친구 이름은?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SummarizeChain \n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here is a revised summary incorporating the new context:\\n\\nIn a neon-lit futuristic Tokyo, a young girl named Miko works as a courier delivering illegal data to earn money for her sick mother\\'s treatment. One day she is tasked with delivering data exposing the Ulph Corporation\\'s oppressive control over citizens. On her way to deliver the data to a bar called \"Grandma\\'s House,\" Miko is chased by Ulph Corporation agents who have heard rumors about the \"Red Cloak\" data carrier and try to intercept it from her. Miko cunningly shakes off the agents and arrives at the bar, where she meets her childhood friend Ryo who has betrayed her by joining the hackers fighting Ulph Corporation. Despite Ryo\\'s anger, Miko gives him the data, deciding to join forces with Ryo to take down Ulph Corporation and free the citizens from its control. Together with the hacker group, Miko and Ryo launch a final battle against Ulph Corporation, using their hacking skills and physical abilities to penetrate the corporation\\'s security. In the process, Miko discovers that Ulph Corporation is involved in her mother\\'s illness. Filled with rage, she vows revenge against Ulph Corporation. After Ulph Corporation falls,'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm_bchat = BedrockChat(credentials_profile_name=\"default\", model_id=\"anthropic.claude-v2\")\n",
    "\n",
    "chain_summ = load_summarize_chain(\n",
    "  llm=llm_bchat,\n",
    "  chain_type=\"refine\"\n",
    ")\n",
    "\n",
    "chain_summ.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The passage provides an overview of systems for building autonomous agents powered by large language models (LLMs). Key points:\\n\\n- LLMs can function as the agent\\'s \"brain\" for planning, memory, and tool use. \\n\\n- Planning involves task decomposition into subgoals and self-reflection to improve. Methods like chain of thought prompt step-by-step reasoning.\\n\\n- Memory includes short-term (in-context learning) and long-term (vector store retrieved via algorithms like MIPS).\\n\\n- Tool use augments LLMs with external APIs and execution capabilities. Examples utilize search engines, calculators, etc.\\n\\n- Case studies demonstrate scientific discovery agents and multi-agent simulations. \\n\\n- Challenges include limited context, long-term planning, unreliable natural language interface.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs_web = loader.load()\n",
    "\n",
    "llm = BedrockChat(credentials_profile_name=\"default\", model_id=\"anthropic.claude-v2\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here is a concise summary of the article on LLM-powered autonomous agents:\\n\\nThe article provides an overview of building agents with large language models (LLMs) as the core controller. Key components of such an agent system include planning mechanisms like task decomposition and self-reflection, memory systems with short-term context and long-term external stores, and tool use by integrating external APIs and models. Case studies demonstrate agents applied to scientific discovery, multi-agent simulations, and other proof-of-concept use cases. Challenges include limited context size, lack of long-term planning capabilities, unreliable natural language interfaces between the LLM and other components. Overall, the article discusses promising progress in augmenting LLMs with additional capabilities to create intelligent autonomous agents, though reliability and planning issues persist.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "pdfread = PyPDFLoader(\"../data/CM5117_20220728.pdf\")\n",
    "docs_pdf = loader.load()\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs_pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼼꼼하고 든든한 도로 위의 매니저\n",
      "하이카자동차보험개인용자동차보험  약관2022. 07. 28 개정 CM\n",
      "자동차상품파트 준법감시인 확인필 제20221957호(유효기간 2022.6.21~2023.6.20)03183  서울시 종로구 세종대로 163  현대해상빌딩\n",
      "대표전화:1899-6782  | direct. hi.co.kr\n"
     ]
    }
   ],
   "source": [
    "import pypdf as pp \n",
    "\n",
    "readpdf = pp.PdfReader(\"../data/CM5117_20220728.pdf\")\n",
    "\n",
    "print(readpdf.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'Perceptron'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      5\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m----> 7\u001b[0m perceptron \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPerceptron\u001b[49m(input_dim\u001b[38;5;241m=\u001b[39minput_dim)\n\u001b[0;32m      8\u001b[0m bce_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(perceptron\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'Perceptron'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "input_dim = 2\n",
    "lr = 0.001\n",
    "\n",
    "perceptron = optim.Perceptron(input_dim=input_dim)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(perceptron.parameters(), lr=lr )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yknlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
